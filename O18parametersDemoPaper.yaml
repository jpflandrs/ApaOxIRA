#   Summary : This is the companion file for
#                                           ApaOxIRA
# A Monte-Carlo simulation of the alteration of the original oxygen isotope composition of biogenic apatites
#   ----
#   See the corresponding publication:
#   "Mitigation of the diagenesis risk in biological apatite δ18O interpretation"
#               Christophe Lécuyer(1) and Jean-Pierre Flandrois(2)
#   (1)LGL-TPE, CNRS UMR5276, ENSL, Univ Lyon, Univ Lyon 1, Institut Universitaire de France, 43 bd du 11 Novembre 1918, 69622 Villeurbanne, France.
#   (2)LBBE, CNRS UMR5558, Univ Lyon, Univ Lyon 1, 43 bd du 11 Novembre 1918, 69622 Villeurbanne, France.
#   ----
#                  This file may be read and modified in a basic text editor, but it is far better to use a more adapted editor like
#                                               Mac OS: BBEedit (or even better Xcode)
#                                               Linux : medit
#                                               Windows : notepad++
#   ----
#   The program is made available under the [CeCILL2.1](http://www.cecill.info/licences/Licence_CeCILL_V2.1-en.txt) licence.
#   ----

#
###########################
#  GENERAL CONSIDERATIONS
###########################
# ApaOxIRA estimate the risk of a false interpretation when considering biological apatite δ18O data (essentially in thanatocenoses) being exempt of a diagenesis effect
# In condition of sedimentary deposits in short time and limited space the distribution of biological apatite δ18O data is expected to be issued from a  population following a Normal Law (H0). But if the samples have been submitted to a diagenesis process the distribution of biological apatite δ18O data do not fit to a Normal Law (blurred signal).
#   -> If the observed apatite δ18O are _not_ following a Normal distribution, there is (following the H0 definition) either a) a diagenesis process or b) the spatio-temporal event that has given the deposit does not correspond to a suffisently limited time or space to allows the Normal Law hypothesis.
#   -> If the biological apatite δ18O data are issued from a Normal distribution, the thanatocenose and the absence of diagenesis is expected but unfortunately the Normal distribution _may have been observed only by chance_, and this is heavilly dependant of the number of samples. ApaOxSis enables to compute the proportion of such "Normal distribution by chance" for a sample of given number within a original population submitted to diagenesis. It estimate the risk level to _disagree with H0_ even if a Normal distribution is observed (risk of over-interpretation). ApaOxIRA enable to choose an optimal sampling scheme that minimize this risk or to abandon the study before any interpretation if the risk in too important.

###########################
#    HOW TO USE
#   ApaOxIRA.py
###########################
# launching the program like this :
#               python3 ApaOxIRA.py -r parameters.yaml resultsFile output_file

#parameters.yaml is _this file_ (any name) remember that YAML is a human-readable data serialization language where identation and white-spaces are signifiant

### Description of the usage:

# ApaOxIRA [-h] [-r | -x | -s ] i o

# positional arguments:
#  i                  parameter file (yaml file, WARNING: structure is mandatory) OR user data
#  o                  The _directory_ that will gather the results
#
# optional arguments:
#  -h, --help         show this help message and exit
#  -r, --Water        Computes the table linking the number of samples to the risk of over-interpretation
#  -x, --Apatite      Same as -r but repeated 30 times
#  -s, --Temperature  User data are given, output is made of several files concerning statistics and the estimated level of risk of over-interpretation
#
# exemples
# python3.11 ApaOxIRA.py -r parameters.yaml resultsFile : "parameters.yaml" = this file; the outputs, here "resultsFile", are a table and a graph linking the number of samples to the risk of over-interpretation.
# python3.11 ApaOxIRA.py -x parameters.yaml resultsFile : "parameters.yaml" = this file; the output, here "resultsFile" looks in -r but repeated 30 times for estimation of the potential variations
# python3.11 ApaOxIRA.py -x User_data resultsFile : "User_data" = one column table of apatite δ18O, the output,here "resultsFile", is a study of the Normality of the biological apatite δ18O data and the risk level corresponding to the sample number.
# --- Note --- that ApaOxIRA is written in python3 and that the optimal version of python is > 3.10: python3.11 is 10% more rapid than python3.10!

###########################
#    HOW IT WORKS
###########################
# ApaOxSis _in silico_ simulation of diagenesis uses a Monte-Carlo process (diagenesis) or chained Monte-Carlo (double diagenesis) process to compute the fate of huge number (typically 1,000,000) of simulated samples submitted to one diagenesis process, optionally two. It is also possible to add a simulation of the experimental error.
# A random sampling of a huge number of populations of number n (simulated sample) is computed and each sample is tested for Normality using two powerful Normality tests. If the two tests are convergents, the simulated population is said to follow a Normal distribution. The ratio of Normal vs total simulated samples give the "Normal distribution by chance" ratio. The standard deviation of this ratio is estimated by a bootstrap process.
# When real data are submitted ("-s") the program computes basic statistics and the two normality tests used in the previous description, as well as graphical outputs (fitting to a Normal distribution, QQ-plot, summary) to facilitate the analysis(1). The level of the risk of "Normal distribution by chance" is also given, so that if a Normal distribution cannot be rejected for the user sample, it is also possible to interpretate knowing the risk. For example, a sample of 50 apatite δ18O is following a Normal distribution but the computed risk is of 11.6%, so we deduce that we cannot take the Normality into account to validate the sample and other type of validation has to be done individually to each sample. A decent level must be discuted : a probability of 5% of risk is certainly optimal, but you may decide to accept a higher level of risk and discuss this choice according to the experimental circonstances. However running the simulation ("-r") with the basic parameters shows that a 60 sample count would led to 4.96 % risk, increasing the number os samples of 10 will fulfill the 5% risk criterium.
#   (1) However note that the graphical analysis cannot be performed during the simulation that will estimate the risk level.
#
# You can describe more precisely your specific paramaters ->

###########################
#   BASIC USE of this file
###########################
    # if the line contains "# !! not a parameter, it must remain unchanged  !!" => this is the description of a python dictionnary key, the program _must_ find it unchanged...
    # else you may find the indication that points out to something that may change, modify with the values of the parameters of your simulation
    # IMPORTANT : the numeric or text is ALWAYS separated from the ":" by _a space_ and the _struture with the white-spaces identation_ is higly significant and must remain unchanged
    # "#" correspond to annotations and explaination
    
    # There are TWO chapters in the parameters, I) is dealing with the physico-chemical model II) concern the formatting of the outputs and the computer
    #
    
###########################
#   MANDATORY DESCRIPTION
#    of the simulation
###########################
parameterdictionary0 :      #dont change the name
    arraysize: 500000    #nb of Monte-Carlo simulations, an integer multiple of 5000 _not less than 250,000_ (wich may be use as an exploratory phase), ideally over 500,000, and not more than 5,000,000. Note that this may be increased automaticaly to obtain an egal number of slides of 5000 for each thread, as with 8 threads (500000/5000)/8 =12.5 then the nb of Monte-Carlo simulations is increased to 520000 as (520000/5000)/8 =13
    sampleNB: 10        #nb of samples, integer
    T: 15               #Temperature (C°) during the diagenesis process, positive integer
    d18OWi: -8.0        #Initial δ18O for water, float
    d18OAi: 20.0        #Initial δ18O for apatite, float
    alpha: 0.05         #the alpha value used to interpretate the statistics, float. Better to use 0.05
    WAlow: 0.05          #the lower W/A ratio during the simulation, float WAlow > 0
    WAhigh: 0.95         #the higher W/A ratio during the simulation, float WAhigh < 1

############################
#        OPTIONS
############################
#     Optional Integration of the experimetal error (or not)
analyticalProcessSimulation : True #False if we dont want to include the experimental error
experimental :
    sigma : 0.05 # usually 0.05 (default) or 0.1

#     Optionally include second diagenesis
#               If another diagenesis phase is needed, change SecondDiagenesis to True
SecondDiagenesis : False # SecondDiagenesis : True will enable a second simulation from the first one
#this correspond to a _second diagenesis_ phase. This increase the computing time
# If another diagenesis phase is needed, the parameters are to be defined here down
parameterdictionary1 :      #dont change the name
                            #Note that alpha, arraysize and sampleNB are not changing
    T1: 40               #Temperature (C°) during the second diagenesis process, positive integer
    d18OWi1: -8.0        #Initial δ18O for water, float
    WAlow1: 0.1          #the lower W/A ratio during the simulation, float WAlow > 0
    WAhigh1: 0.5         #the higher W/A ratio during the simulation, float WAhigh < 1


############################
#        EXPERT USE
############################
# STEP-WISE INCREASE OF THE NUMBER OF SAMPLES: the "-r" or "-x" options _no_ experimental data submitted!
# This is used to compute the risk linked to a sampling sheme (number of samples): the idea is to use a sampling scheme that minimize the risk to get a Normal population only by chance.
# The -r option return a table and a graph of the estimated risk to wrongly conclude to a Normal population
# The simulation will to be done iteratively with programmed changes of the sampleNB parameter. Note that you can begin with sampleNB: 20 and adjust stepNumbers and stepAmplitude to get the desired range of sampleNB to test.
#
stepwiseIncreaseNbSamples : True    #if True, the stepwise Increase of the number of sample is launched
stepping:
    stepNumbers : 40     #the number of steps to generate: an integer
    stepAmplitude : 2   #the amplitude of a step: an integer

#if both steps options are True, _an error will be generated_


### Number of threads
threadsCount: auto            # an integer, else <auto> enables the optimization of the number of threads. Note that the speed will not be decreased proportionally with the number of threads: as expected with multithreading there is an optimum speed-efficacy.  Typically on a iMacPro (2017) with 3 GHz Intel Xeon W 20 threads: the speed increases rapidly until 10 threads, then the gain in speed is low (a very slowly growing plateau). Exagerating the number of thread as no adverse effect on the speed but impairs the electric consumption (drop in efficacy). Note that the speed may eventually fall if the number of thread is exagerately high.
